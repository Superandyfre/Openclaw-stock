"""
RedditÁ§æÂå∫ÁõëÊéßÂô®

ÁõëÊéßÂä†ÂØÜË¥ßÂ∏ÅÁõ∏ÂÖ≥ÁöÑRedditÁ§æÂå∫ÔºàsubredditÔºâÔºåÂàÜÊûêËÆ®ËÆ∫ÁÉ≠Â∫¶ÂíåÊï£Êà∑ÊÉÖÁª™

ÂÖçË¥π‰ΩøÁî®Reddit API
"""
import asyncio
import re
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
from loguru import logger

try:
    import praw
    from praw.models import Submission, Comment
    PRAW_AVAILABLE = True
except ImportError:
    PRAW_AVAILABLE = False
    logger.warning("prawÊú™ÂÆâË£ÖÔºåRedditÁõëÊéßÂ∞Ü‰ΩøÁî®Ê®°ÊãüÊï∞ÊçÆ")


class RedditCommunityMonitor:
    """
    RedditÁ§æÂå∫ÁõëÊéßÂô®
    
    ÁõëÊéßÂä†ÂØÜË¥ßÂ∏ÅÁõ∏ÂÖ≥ÁöÑÁÉ≠Èó®subreddit
    ÈúÄË¶ÅÂÖçË¥πReddit APIÂØÜÈí•
    """
    
    # È¢ÑËÆæÁöÑÈáçË¶ÅÁ§æÂå∫ÂàóË°®
    IMPORTANT_SUBREDDITS = {
        'CryptoCurrency': {
            'name': 'Âä†ÂØÜË¥ßÂ∏ÅÁªºÂêà',
            'members': '7.5M+',
            'description': 'ÊúÄÂ§ßÁöÑÂä†ÂØÜË¥ßÂ∏ÅÁ§æÂå∫',
            'keywords': ['Bitcoin', 'Ethereum', 'altcoin', 'trading', 'HODL']
        },
        'Bitcoin': {
            'name': 'ÊØîÁâπÂ∏Å',
            'members': '6.0M+',
            'description': 'ÊØîÁâπÂ∏ÅÂÆòÊñπÁ§æÂå∫',
            'keywords': ['BTC', 'mining', 'Lightning', 'halving', 'adoption']
        },
        'ethtrader': {
            'name': '‰ª•Â§™Âùä‰∫§Êòì',
            'members': '1.5M+',
            'description': '‰ª•Â§™Âùä‰∫§ÊòìËÆ®ËÆ∫',
            'keywords': ['ETH', 'DeFi', 'gas', 'Layer2', 'staking']
        },
        'wallstreetbets': {
            'name': 'ÂçéÂ∞îË°óËµåÂú∫',
            'members': '16M+',
            'description': 'Êï£Êà∑ÊÉÖÁª™È£éÂêëÊ†áÔºàÂåÖÂê´Âä†ÂØÜËÆ®ËÆ∫Ôºâ',
            'keywords': ['crypto', 'Bitcoin', 'moon', 'diamond hands', 'YOLO']
        },
        'CryptoMarkets': {
            'name': 'Âä†ÂØÜÂ∏ÇÂú∫',
            'members': '2.5M+',
            'description': 'Âä†ÂØÜË¥ßÂ∏ÅÂ∏ÇÂú∫ÂàÜÊûê',
            'keywords': ['trading', 'TA', 'chart', 'support', 'resistance']
        },
        'btc': {
            'name': 'ÊØîÁâπÂ∏ÅÊäÄÊúØ',
            'members': '400K+',
            'description': 'ÊØîÁâπÂ∏ÅÊäÄÊúØËÆ®ËÆ∫',
            'keywords': ['protocol', 'node', 'blockchain', 'development']
        }
    }
    
    # ÈáçË¶Å‰∫∫Áâ©ÂÖ≥ÈîÆËØç
    INFLUENCER_KEYWORDS = {
        'elon_musk': ['Elon Musk', 'ElonMusk', 'Elon', 'Tesla', 'SpaceX'],
        'michael_saylor': ['Michael Saylor', 'Saylor', 'MicroStrategy'],
        'cz': ['CZ', 'Changpeng Zhao', 'Binance CEO'],
        'vitalik': ['Vitalik', 'Vitalik Buterin', 'Ethereum founder'],
        'cathie_wood': ['Cathie Wood', 'ARK Invest', 'ARKK'],
        'gary_gensler': ['Gary Gensler', 'SEC Chair'],
    }
    
    def __init__(
        self,
        client_id: Optional[str] = None,
        client_secret: Optional[str] = None,
        user_agent: str = 'OpenClaw Crypto Monitor',
        subreddits: Optional[List[str]] = None
    ):
        """
        ÂàùÂßãÂåñRedditÁõëÊéßÂô®
        
        Args:
            client_id: Reddit API Client IDÔºà‰ªé https://www.reddit.com/prefs/apps Ëé∑ÂèñÔºâ
            client_secret: Reddit API Client Secret
            user_agent: User AgentÂ≠óÁ¨¶‰∏≤
            subreddits: Ë¶ÅÁõëÊéßÁöÑÁ§æÂå∫ÂàóË°®
        """
        self.client_id = client_id
        self.client_secret = client_secret
        self.user_agent = user_agent
        
        # ÁõëÊéßÁöÑÁ§æÂå∫ÔºàÈªòËÆ§ÁõëÊéßÊâÄÊúâÈáçË¶ÅÁ§æÂå∫Ôºâ
        if subreddits:
            self.subreddits = subreddits
        else:
            self.subreddits = list(self.IMPORTANT_SUBREDDITS.keys())
        
        # RedditÂÆ¢Êà∑Á´Ø
        self.reddit = None
        
        # Êï∞ÊçÆÁºìÂ≠ò
        self.post_cache: Dict[str, List[Dict[str, Any]]] = {}
        self.analysis_cache: Dict[str, List[Dict[str, Any]]] = {}
        
        logger.info(f"‚úÖ RedditCommunityMonitor ÂàùÂßãÂåñ")
        logger.info(f"   ÁõëÊéßÁ§æÂå∫: {len(self.subreddits)}‰∏™")
    
    def connect(self):
        """ËøûÊé•Âà∞Reddit API"""
        if not PRAW_AVAILABLE:
            logger.warning("PRAWÊú™ÂÆâË£ÖÔºå‰ΩøÁî®Ê®°ÊãüÊ®°Âºè")
            return False
        
        if not self.client_id or not self.client_secret:
            logger.warning("Êú™Êèê‰æõReddit APIÂá≠ËØÅÔºå‰ΩøÁî®Ê®°ÊãüÊ®°Âºè")
            return False
        
        try:
            self.reddit = praw.Reddit(
                client_id=self.client_id,
                client_secret=self.client_secret,
                user_agent=self.user_agent
            )
            
            # ÊµãËØïËøûÊé•
            self.reddit.user.me()
            
            logger.info("‚úÖ Â∑≤ËøûÊé•Âà∞Reddit API")
            return True
        except Exception as e:
            logger.error(f"ËøûÊé•RedditÂ§±Ë¥•: {e}")
            logger.info("Â∞Ü‰ΩøÁî®Ê®°ÊãüÊ®°Âºè")
            return False
    
    def fetch_hot_posts(
        self,
        subreddit_name: str,
        limit: int = 25,
        time_filter: str = 'day'
    ) -> List[Dict[str, Any]]:
        """
        Ëé∑ÂèñÁÉ≠Èó®Â∏ñÂ≠ê
        
        Args:
            subreddit_name: Á§æÂå∫ÂêçÁß∞
            limit: Ëé∑ÂèñÊï∞Èáè
            time_filter: Êó∂Èó¥ËøáÊª§ (hour, day, week, month, year, all)
        
        Returns:
            Â∏ñÂ≠êÂàóË°®
        """
        # Â¶ÇÊûúÊ≤°ÊúâËøûÊé•Ôºå‰ΩøÁî®Ê®°ÊãüÊï∞ÊçÆ
        if not self.reddit or not PRAW_AVAILABLE:
            return self._generate_mock_posts(subreddit_name, limit)
        
        try:
            subreddit = self.reddit.subreddit(subreddit_name)
            posts = []
            
            for submission in subreddit.hot(limit=limit):
                # ËÆ°ÁÆóÂ∏ñÂ≠êÂπ¥ÈæÑÔºàÂ∞èÊó∂Ôºâ
                post_age = (datetime.now() - datetime.fromtimestamp(submission.created_utc)).total_seconds() / 3600
                
                # Âè™Ëé∑ÂèñÊúÄËøë24Â∞èÊó∂ÁöÑÂ∏ñÂ≠ê
                if post_age > 24:
                    continue
                
                posts.append({
                    'id': submission.id,
                    'subreddit': subreddit_name,
                    'title': submission.title,
                    'text': submission.selftext[:500] if submission.selftext else '',
                    'author': str(submission.author),
                    'score': submission.score,
                    'upvote_ratio': submission.upvote_ratio,
                    'num_comments': submission.num_comments,
                    'created_utc': datetime.fromtimestamp(submission.created_utc).isoformat(),
                    'url': submission.url,
                    'flair': submission.link_flair_text,
                    'timestamp': datetime.now().isoformat()
                })
            
            logger.info(f"Ëé∑Âèñ r/{subreddit_name} ÁöÑ {len(posts)} ‰∏™ÁÉ≠Èó®Â∏ñÂ≠ê")
            return posts
        
        except Exception as e:
            logger.error(f"Ëé∑ÂèñRedditÂ∏ñÂ≠êÂ§±Ë¥• r/{subreddit_name}: {e}")
            return self._generate_mock_posts(subreddit_name, limit)
    
    def analyze_posts(
        self,
        posts: List[Dict[str, Any]],
        subreddit_name: str
    ) -> Dict[str, Any]:
        """
        ÂàÜÊûêÁ§æÂå∫Â∏ñÂ≠ê
        
        Args:
            posts: Â∏ñÂ≠êÂàóË°®
            subreddit_name: Á§æÂå∫ÂêçÁß∞
        
        Returns:
            ÂàÜÊûêÁªìÊûú
        """
        if not posts:
            return {'error': 'Êó†Â∏ñÂ≠êÊï∞ÊçÆ'}
        
        subreddit_info = self.IMPORTANT_SUBREDDITS.get(subreddit_name, {})
        keywords = subreddit_info.get('keywords', [])
        
        # 1. ÂÖ≥ÈîÆËØçÁªüËÆ°
        keyword_counts = {kw: 0 for kw in keywords}
        for post in posts:
            title = post.get('title', '').lower()
            text = post.get('text', '').lower()
            combined_text = title + ' ' + text
            
            for kw in keywords:
                if kw.lower() in combined_text:
                    keyword_counts[kw] += 1
        
        # 2. ÈáçË¶Å‰∫∫Áâ©ÊèêÂèä
        influencer_mentions = {}
        for influencer, keywords_list in self.INFLUENCER_KEYWORDS.items():
            count = 0
            for post in posts:
                title = post.get('title', '')
                text = post.get('text', '')
                combined = title + ' ' + text
                
                if any(kw in combined for kw in keywords_list):
                    count += 1
            
            if count > 0:
                influencer_mentions[influencer] = count
        
        # 3. ÊÉÖÁª™ÂàÜÊûêÔºàÂü∫‰∫éÊ†áÈ¢òÂíåÂÜÖÂÆπÂÖ≥ÈîÆËØçÔºâ
        bullish_keywords = [
            'bullish', 'moon', 'pump', 'rally', 'surge', 'breakout', 'ATH', 
            'buy', 'buying', 'accumulate', 'HODL', 'diamond hands', 'to the moon'
        ]
        bearish_keywords = [
            'bearish', 'dump', 'crash', 'drop', 'fall', 'sell', 'selling',
            'correction', 'bubble', 'scam', 'rug pull', 'paper hands'
        ]
        
        bullish_count = 0
        bearish_count = 0
        
        for post in posts:
            title = post.get('title', '').lower()
            text = post.get('text', '').lower()
            combined = title + ' ' + text
            
            bullish_count += sum(1 for kw in bullish_keywords if kw in combined)
            bearish_count += sum(1 for kw in bearish_keywords if kw in combined)
        
        total_sentiment_signals = bullish_count + bearish_count
        if total_sentiment_signals > 0:
            sentiment_score = (bullish_count - bearish_count) / total_sentiment_signals
        else:
            sentiment_score = 0
        
        # ÊÉÖÁª™ÂàÜÁ±ª
        if sentiment_score > 0.3:
            sentiment_label = 'BULLISH'
        elif sentiment_score > 0.1:
            sentiment_label = 'SLIGHTLY_BULLISH'
        elif sentiment_score < -0.3:
            sentiment_label = 'BEARISH'
        elif sentiment_score < -0.1:
            sentiment_label = 'SLIGHTLY_BEARISH'
        else:
            sentiment_label = 'NEUTRAL'
        
        # 4. ‰∫íÂä®ÁÉ≠Â∫¶
        total_score = sum(post.get('score', 0) for post in posts)
        total_comments = sum(post.get('num_comments', 0) for post in posts)
        avg_score = total_score / len(posts) if posts else 0
        avg_comments = total_comments / len(posts) if posts else 0
        avg_upvote_ratio = sum(post.get('upvote_ratio', 0) for post in posts) / len(posts) if posts else 0
        
        # 5. ÁÉ≠Èó®Â∏ñÂ≠êÔºàÊåâÂæóÂàÜÊéíÂ∫èÂâç5Ôºâ
        top_posts = sorted(
            posts,
            key=lambda x: x.get('score', 0),
            reverse=True
        )[:5]
        
        # 6. ËÆ®ËÆ∫ÁÉ≠Â∫¶Ë∂ãÂäøÔºàÂ¶ÇÊûúÊúâÁºìÂ≠òÔºâ
        trend = 'UNKNOWN'
        if subreddit_name in self.analysis_cache and self.analysis_cache[subreddit_name]:
            last_analysis = self.analysis_cache[subreddit_name][-1]
            last_avg_score = last_analysis.get('engagement', {}).get('avg_score', 0)
            
            if avg_score > last_avg_score * 1.2:
                trend = 'RISING'
            elif avg_score < last_avg_score * 0.8:
                trend = 'FALLING'
            else:
                trend = 'STABLE'
        
        analysis = {
            'subreddit': subreddit_name,
            'subreddit_name': subreddit_info.get('name', subreddit_name),
            'members': subreddit_info.get('members', 'Unknown'),
            'timestamp': datetime.now().isoformat(),
            'post_count': len(posts),
            'keyword_mentions': keyword_counts,
            'influencer_mentions': influencer_mentions,
            'sentiment': {
                'score': sentiment_score,
                'label': sentiment_label,
                'bullish_signals': bullish_count,
                'bearish_signals': bearish_count
            },
            'engagement': {
                'total_score': total_score,
                'total_comments': total_comments,
                'avg_score': avg_score,
                'avg_comments': avg_comments,
                'avg_upvote_ratio': avg_upvote_ratio
            },
            'trend': trend,
            'top_posts': [
                {
                    'title': post['title'],
                    'score': post.get('score', 0),
                    'comments': post.get('num_comments', 0),
                    'upvote_ratio': post.get('upvote_ratio', 0)
                }
                for post in top_posts
            ]
        }
        
        # ÁºìÂ≠òÁªìÊûú
        if subreddit_name not in self.post_cache:
            self.post_cache[subreddit_name] = []
        if subreddit_name not in self.analysis_cache:
            self.analysis_cache[subreddit_name] = []
        
        self.post_cache[subreddit_name].extend(posts)
        self.analysis_cache[subreddit_name].append(analysis)
        
        # ÈôêÂà∂ÁºìÂ≠òÂ§ßÂ∞è
        if len(self.post_cache[subreddit_name]) > 200:
            self.post_cache[subreddit_name] = self.post_cache[subreddit_name][-200:]
        if len(self.analysis_cache[subreddit_name]) > 100:
            self.analysis_cache[subreddit_name] = self.analysis_cache[subreddit_name][-100:]
        
        return analysis
    
    def monitor_all_subreddits(
        self,
        limit_per_subreddit: int = 25
    ) -> List[Dict[str, Any]]:
        """
        ÁõëÊéßÊâÄÊúâÈÖçÁΩÆÁöÑÁ§æÂå∫
        
        Args:
            limit_per_subreddit: ÊØè‰∏™Á§æÂå∫Ëé∑ÂèñÂ∏ñÂ≠êÊï∞
        
        Returns:
            ÊâÄÊúâÁ§æÂå∫ÁöÑÂàÜÊûêÁªìÊûú
        """
        logger.info(f"\n{'='*70}")
        logger.info(f"üîÑ ÂºÄÂßãRedditÁ§æÂå∫ÁõëÊéß - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"{'='*70}")
        
        results = []
        
        for subreddit in self.subreddits:
            try:
                # Ëé∑ÂèñÂ∏ñÂ≠ê
                posts = self.fetch_hot_posts(subreddit, limit=limit_per_subreddit)
                
                # ÂàÜÊûêÂ∏ñÂ≠ê
                if posts:
                    analysis = self.analyze_posts(posts, subreddit)
                    results.append(analysis)
                    
                    # ÊâìÂç∞ÊëòË¶Å
                    sentiment = analysis.get('sentiment', {})
                    engagement = analysis.get('engagement', {})
                    
                    logger.info(f"üìä r/{subreddit}: {analysis['post_count']}‰∏™Â∏ñÂ≠ê, "
                              f"ÊÉÖÁª™={sentiment['label']}, "
                              f"Âπ≥Âùá{engagement['avg_score']:.0f}ÂàÜ/{engagement['avg_comments']:.0f}ËØÑËÆ∫")
                
                # ÈÅøÂÖçÈÄüÁéáÈôêÂà∂
                import time
                time.sleep(2)
            
            except Exception as e:
                logger.error(f"ÁõëÊéßÁ§æÂå∫Â§±Ë¥• r/{subreddit}: {e}")
        
        logger.info(f"{'='*70}")
        logger.info(f"‚úÖ RedditÁõëÊéßÂÆåÊàêÔºåÂÖ±ÂàÜÊûê {len(results)} ‰∏™Á§æÂå∫")
        logger.info(f"{'='*70}\n")
        
        return results
    
    def _generate_mock_posts(self, subreddit: str, limit: int) -> List[Dict[str, Any]]:
        """ÁîüÊàêÊ®°ÊãüÂ∏ñÂ≠êÔºàÁî®‰∫éÊµãËØïÔºâ"""
        import random
        
        mock_titles = [
            "Bitcoin just broke $67k! Is this the start of the bull run? üöÄ",
            "Ethereum gas fees are finally down to reasonable levels",
            "PSA: Don't FOMO into altcoins at ATH, learned the hard way",
            "Michael Saylor's MicroStrategy buys another 500 BTC",
            "SEC delays Bitcoin ETF decision again - thoughts?",
            "Vitalik's new Ethereum roadmap looks promising",
            "Chart analysis: BTC might test $70k resistance soon",
            "Just started DCA into Bitcoin, wish me luck!",
            "Warning: New scam targeting crypto holders on social media",
            "Unpopular opinion: Most altcoins won't survive the next bear market"
        ]
        
        posts = []
        base_time = datetime.now()
        
        for i in range(min(limit, len(mock_titles) * 2)):
            posts.append({
                'id': f'mock_{i}',
                'subreddit': subreddit,
                'title': random.choice(mock_titles),
                'text': 'Mock post content for testing purposes.',
                'author': f'user{random.randint(1000, 9999)}',
                'score': random.randint(50, 5000),
                'upvote_ratio': random.uniform(0.7, 0.98),
                'num_comments': random.randint(10, 500),
                'created_utc': (base_time - timedelta(hours=random.randint(1, 23))).isoformat(),
                'url': f'https://reddit.com/r/{subreddit}/mock_{i}',
                'flair': random.choice(['Discussion', 'News', 'Analysis', 'Comedy']),
                'timestamp': datetime.now().isoformat()
            })
        
        return posts
    
    def get_summary_report(self, analyses: List[Dict[str, Any]]) -> str:
        """
        ÁîüÊàêRedditÁõëÊéßÊëòË¶ÅÊä•Âëä
        
        Args:
            analyses: Á§æÂå∫ÂàÜÊûêÁªìÊûúÂàóË°®
        
        Returns:
            Êä•ÂëäÊñáÊú¨
        """
        if not analyses:
            return "Êó†RedditÁõëÊéßÊï∞ÊçÆ"
        
        report = []
        report.append("\n" + "="*70)
        report.append("üó£Ô∏è  RedditÁ§æÂå∫ÁõëÊéßÊä•Âëä")
        report.append("="*70)
        report.append(f"Êó∂Èó¥: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"ÁõëÊéßÁ§æÂå∫: {len(analyses)}‰∏™")
        report.append("")
        
        # Êï¥‰ΩìÊÉÖÁª™ÁªüËÆ°
        total_bullish = sum(1 for a in analyses if a.get('sentiment', {}).get('label') in ['BULLISH', 'SLIGHTLY_BULLISH'])
        total_bearish = sum(1 for a in analyses if a.get('sentiment', {}).get('label') in ['BEARISH', 'SLIGHTLY_BEARISH'])
        total_neutral = len(analyses) - total_bullish - total_bearish
        
        report.append("„ÄêÊï¥‰ΩìÊÉÖÁª™„Äë")
        report.append(f"  ÁúãÊ∂®Á§æÂå∫: {total_bullish}‰∏™")
        report.append(f"  ÁúãË∑åÁ§æÂå∫: {total_bearish}‰∏™")
        report.append(f"  ‰∏≠ÊÄßÁ§æÂå∫: {total_neutral}‰∏™")
        report.append("")
        
        # ÈáçË¶Å‰∫∫Áâ©ÊèêÂèäÊ±áÊÄª
        all_influencer_mentions = {}
        for analysis in analyses:
            for influencer, count in analysis.get('influencer_mentions', {}).items():
                if influencer not in all_influencer_mentions:
                    all_influencer_mentions[influencer] = 0
                all_influencer_mentions[influencer] += count
        
        if all_influencer_mentions:
            report.append("„ÄêÈáçË¶Å‰∫∫Áâ©ÊèêÂèä„Äë")
            for influencer, count in sorted(all_influencer_mentions.items(), key=lambda x: x[1], reverse=True):
                name = influencer.replace('_', ' ').title()
                report.append(f"  {name}: {count}Ê¨°")
            report.append("")
        
        # ÂêÑÁ§æÂå∫ËØ¶ÊÉÖ
        report.append("„ÄêÁ§æÂå∫ËØ¶ÊÉÖ„Äë")
        for analysis in analyses:
            subreddit_name = analysis.get('subreddit_name', analysis['subreddit'])
            post_count = analysis['post_count']
            sentiment = analysis.get('sentiment', {})
            engagement = analysis.get('engagement', {})
            
            report.append(f"\n  üìä {subreddit_name} (r/{analysis['subreddit']})")
            report.append(f"     ÊàêÂëò: {analysis.get('members', 'Unknown')}")
            report.append(f"     Â∏ñÂ≠êÊï∞: {post_count}")
            report.append(f"     ÊÉÖÁª™: {sentiment.get('label', 'UNKNOWN')} (ÂæóÂàÜ: {sentiment.get('score', 0):.2f})")
            report.append(f"     ‰∫íÂä®: Âπ≥Âùá{engagement.get('avg_score', 0):.0f}ÂàÜ, {engagement.get('avg_comments', 0):.0f}ËØÑËÆ∫")
            report.append(f"     ÊîØÊåÅÁéá: {engagement.get('avg_upvote_ratio', 0)*100:.1f}%")
            report.append(f"     ÁÉ≠Â∫¶Ë∂ãÂäø: {analysis.get('trend', 'UNKNOWN')}")
            
            # ÂÖ≥ÈîÆËØçÊèêÂèä
            keyword_mentions = analysis.get('keyword_mentions', {})
            top_keywords = sorted(keyword_mentions.items(), key=lambda x: x[1], reverse=True)[:3]
            if top_keywords:
                keywords_str = ', '.join([f"{kw}({count})" for kw, count in top_keywords if count > 0])
                if keywords_str:
                    report.append(f"     ÁÉ≠ËØç: {keywords_str}")
        
        report.append("\n" + "="*70)
        
        return '\n'.join(report)
