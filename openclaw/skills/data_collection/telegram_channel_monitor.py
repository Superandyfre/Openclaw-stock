"""
Telegramå…¬å¼€é¢‘é“ç›‘æ§å™¨

ç›‘æ§é‡è¦äººç‰©/æœºæ„çš„Telegramå…¬å¼€é¢‘é“ï¼Œè·å–å®æ—¶æ¶ˆæ¯å’Œå¸‚åœºæƒ…ç»ª

å…è´¹ä½¿ç”¨ï¼Œæ— APIè´¹ç”¨
"""
import asyncio
import re
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
from loguru import logger

try:
    from telethon import TelegramClient
    from telethon.tl.types import Message
    TELETHON_AVAILABLE = True
except ImportError:
    TELETHON_AVAILABLE = False
    logger.warning("telethonæœªå®‰è£…ï¼ŒTelegramç›‘æ§å°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")


class TelegramChannelMonitor:
    """
    Telegramå…¬å¼€é¢‘é“ç›‘æ§å™¨
    
    ç›‘æ§åŠ å¯†è´§å¸ç›¸å…³çš„é‡è¦Telegramé¢‘é“
    å®Œå…¨å…è´¹ï¼Œæ— éœ€APIå¯†é’¥ï¼ˆä»…éœ€Telegramè´¦å·ï¼‰
    """
    
    # é¢„è®¾çš„é‡è¦é¢‘é“åˆ—è¡¨
    IMPORTANT_CHANNELS = {
        'whale_alert': {
            'username': 'whale_alert',
            'name': 'å·¨é²¸è½¬è´¦å‘Šè­¦',
            'description': 'å®æ—¶è¿½è¸ªå¤§é¢åŠ å¯†è´§å¸è½¬è´¦',
            'keywords': ['BTC', 'ETH', 'USDT', 'transferred', 'whale']
        },
        'cointelegraph': {
            'username': 'cointelegraph',
            'name': 'CoinTelegraphæ–°é—»',
            'description': 'åŠ å¯†è´§å¸æ–°é—»å¿«è®¯',
            'keywords': ['Bitcoin', 'Ethereum', 'crypto', 'market', 'price']
        },
        'coindesk': {
            'username': 'CoinDesk',
            'name': 'CoinDeskæ–°é—»',
            'description': 'åŠ å¯†è´§å¸è¡Œä¸šæ–°é—»',
            'keywords': ['Bitcoin', 'Ethereum', 'regulation', 'adoption']
        },
        'binance_announcements': {
            'username': 'binance_announcements',
            'name': 'Binanceå®˜æ–¹å…¬å‘Š',
            'description': 'Binanceäº¤æ˜“æ‰€å®˜æ–¹å…¬å‘Š',
            'keywords': ['listing', 'delisting', 'maintenance', 'promotion']
        },
        'crypto_news_official': {
            'username': 'crypto_news_official',
            'name': 'åŠ å¯†æ–°é—»èšåˆ',
            'description': 'åŠ å¯†è´§å¸æ–°é—»èšåˆé¢‘é“',
            'keywords': ['Bitcoin', 'Ethereum', 'altcoin', 'DeFi', 'NFT']
        }
    }
    
    # é‡è¦äººç‰©å…³é”®è¯ï¼ˆç”¨äºè¯†åˆ«æåŠï¼‰
    INFLUENCER_KEYWORDS = {
        'elon_musk': ['Elon Musk', 'ElonMusk', '@elonmusk', 'Tesla', 'SpaceX'],
        'michael_saylor': ['Michael Saylor', 'MicroStrategy', '@saylor'],
        'cz': ['CZ', 'Changpeng Zhao', 'Binance CEO', '@cz_binance'],
        'vitalik': ['Vitalik', 'Vitalik Buterin', 'Ethereum founder'],
        'cathie_wood': ['Cathie Wood', 'ARK Invest', 'ARKK'],
        'gary_gensler': ['Gary Gensler', 'SEC Chair', 'SEC'],
        'christine_lagarde': ['Christine Lagarde', 'ECB', 'European Central Bank']
    }
    
    def __init__(
        self,
        api_id: Optional[int] = None,
        api_hash: Optional[str] = None,
        phone: Optional[str] = None,
        session_name: str = 'telegram_monitor',
        channels: Optional[List[str]] = None
    ):
        """
        åˆå§‹åŒ–Telegramç›‘æ§å™¨
        
        Args:
            api_id: Telegram API IDï¼ˆä» https://my.telegram.org è·å–ï¼‰
            api_hash: Telegram API Hash
            phone: æ‰‹æœºå·ï¼ˆç”¨äºé¦–æ¬¡ç™»å½•ï¼‰
            session_name: ä¼šè¯æ–‡ä»¶å
            channels: è¦ç›‘æ§çš„é¢‘é“åˆ—è¡¨ï¼ˆusernameï¼‰
        """
        self.api_id = api_id
        self.api_hash = api_hash
        self.phone = phone
        self.session_name = session_name
        
        # ç›‘æ§çš„é¢‘é“ï¼ˆé»˜è®¤ç›‘æ§æ‰€æœ‰é‡è¦é¢‘é“ï¼‰
        if channels:
            self.channels = channels
        else:
            self.channels = list(self.IMPORTANT_CHANNELS.keys())
        
        # æ¶ˆæ¯ç¼“å­˜
        self.message_cache: Dict[str, List[Dict[str, Any]]] = {}
        self.last_check_time: Dict[str, datetime] = {}
        
        # Telegramå®¢æˆ·ç«¯
        self.client = None
        
        logger.info(f"âœ… TelegramChannelMonitor åˆå§‹åŒ–")
        logger.info(f"   ç›‘æ§é¢‘é“: {len(self.channels)}ä¸ª")
    
    async def connect(self):
        """è¿æ¥åˆ°Telegram"""
        if not TELETHON_AVAILABLE:
            logger.warning("Telethonæœªå®‰è£…ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
            return False
        
        if not self.api_id or not self.api_hash:
            logger.warning("æœªæä¾›Telegram APIå‡­è¯ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
            return False
        
        try:
            self.client = TelegramClient(self.session_name, self.api_id, self.api_hash)
            await self.client.start(phone=self.phone)
            logger.info("âœ… å·²è¿æ¥åˆ°Telegram")
            return True
        except Exception as e:
            logger.error(f"è¿æ¥Telegramå¤±è´¥: {e}")
            return False
    
    async def disconnect(self):
        """æ–­å¼€è¿æ¥"""
        if self.client:
            await self.client.disconnect()
            logger.info("å·²æ–­å¼€Telegramè¿æ¥")
    
    async def fetch_channel_messages(
        self,
        channel_username: str,
        limit: int = 20,
        since_minutes: int = 60
    ) -> List[Dict[str, Any]]:
        """
        è·å–é¢‘é“æœ€æ–°æ¶ˆæ¯
        
        Args:
            channel_username: é¢‘é“ç”¨æˆ·åï¼ˆä¸å«@ï¼‰
            limit: è·å–æ¶ˆæ¯æ•°é‡
            since_minutes: è·å–å¤šå°‘åˆ†é’Ÿå†…çš„æ¶ˆæ¯
        
        Returns:
            æ¶ˆæ¯åˆ—è¡¨
        """
        # å¦‚æœæ²¡æœ‰è¿æ¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
        if not self.client or not TELETHON_AVAILABLE:
            return self._generate_mock_messages(channel_username, limit)
        
        try:
            # è·å–é¢‘é“å®ä½“
            channel = await self.client.get_entity(channel_username)
            
            # è·å–æ¶ˆæ¯
            messages = []
            since_time = datetime.now() - timedelta(minutes=since_minutes)
            
            async for message in self.client.iter_messages(channel, limit=limit):
                # åªè·å–æŒ‡å®šæ—¶é—´å†…çš„æ¶ˆæ¯
                if message.date.replace(tzinfo=None) < since_time:
                    break
                
                if message.text:
                    messages.append({
                        'id': message.id,
                        'channel': channel_username,
                        'text': message.text,
                        'date': message.date.isoformat(),
                        'views': message.views or 0,
                        'forwards': message.forwards or 0,
                        'timestamp': datetime.now().isoformat()
                    })
            
            logger.info(f"è·å– @{channel_username} çš„ {len(messages)} æ¡æ¶ˆæ¯")
            return messages
        
        except Exception as e:
            logger.error(f"è·å–é¢‘é“æ¶ˆæ¯å¤±è´¥ @{channel_username}: {e}")
            return self._generate_mock_messages(channel_username, limit)
    
    def analyze_messages(
        self,
        messages: List[Dict[str, Any]],
        channel_username: str
    ) -> Dict[str, Any]:
        """
        åˆ†æé¢‘é“æ¶ˆæ¯
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            channel_username: é¢‘é“ç”¨æˆ·å
        
        Returns:
            åˆ†æç»“æœ
        """
        if not messages:
            return {'error': 'æ— æ¶ˆæ¯æ•°æ®'}
        
        channel_info = self.IMPORTANT_CHANNELS.get(channel_username, {})
        keywords = channel_info.get('keywords', [])
        
        # 1. å…³é”®è¯åŒ¹é…ç»Ÿè®¡
        keyword_counts = {kw: 0 for kw in keywords}
        for msg in messages:
            text = msg.get('text', '').lower()
            for kw in keywords:
                if kw.lower() in text:
                    keyword_counts[kw] += 1
        
        # 2. é‡è¦äººç‰©æåŠæ£€æµ‹
        influencer_mentions = {}
        for influencer, keywords_list in self.INFLUENCER_KEYWORDS.items():
            count = 0
            for msg in messages:
                text = msg.get('text', '')
                if any(kw in text for kw in keywords_list):
                    count += 1
            if count > 0:
                influencer_mentions[influencer] = count
        
        # 3. æƒ…ç»ªåˆ†æï¼ˆç®€å•åŸºäºå…³é”®è¯ï¼‰
        positive_keywords = ['bullish', 'moon', 'pump', 'rally', 'surge', 'breakout', 'ATH', 'adoption']
        negative_keywords = ['bearish', 'dump', 'crash', 'drop', 'fall', 'sell-off', 'correction', 'regulation']
        
        positive_count = 0
        negative_count = 0
        
        for msg in messages:
            text = msg.get('text', '').lower()
            positive_count += sum(1 for kw in positive_keywords if kw in text)
            negative_count += sum(1 for kw in negative_keywords if kw in text)
        
        total_sentiment_signals = positive_count + negative_count
        if total_sentiment_signals > 0:
            sentiment_score = (positive_count - negative_count) / total_sentiment_signals
        else:
            sentiment_score = 0
        
        # æƒ…ç»ªåˆ†ç±»
        if sentiment_score > 0.3:
            sentiment_label = 'BULLISH'
        elif sentiment_score > 0.1:
            sentiment_label = 'SLIGHTLY_BULLISH'
        elif sentiment_score < -0.3:
            sentiment_label = 'BEARISH'
        elif sentiment_score < -0.1:
            sentiment_label = 'SLIGHTLY_BEARISH'
        else:
            sentiment_label = 'NEUTRAL'
        
        # 4. äº’åŠ¨çƒ­åº¦
        total_views = sum(msg.get('views', 0) for msg in messages)
        total_forwards = sum(msg.get('forwards', 0) for msg in messages)
        avg_views = total_views / len(messages) if messages else 0
        avg_forwards = total_forwards / len(messages) if messages else 0
        
        # 5. çƒ­é—¨æ¶ˆæ¯ï¼ˆè½¬å‘æ•°æœ€å¤šçš„å‰3æ¡ï¼‰
        top_messages = sorted(
            messages,
            key=lambda x: x.get('forwards', 0),
            reverse=True
        )[:3]
        
        analysis = {
            'channel': channel_username,
            'channel_name': channel_info.get('name', channel_username),
            'timestamp': datetime.now().isoformat(),
            'message_count': len(messages),
            'keyword_mentions': keyword_counts,
            'influencer_mentions': influencer_mentions,
            'sentiment': {
                'score': sentiment_score,
                'label': sentiment_label,
                'positive_signals': positive_count,
                'negative_signals': negative_count
            },
            'engagement': {
                'total_views': total_views,
                'total_forwards': total_forwards,
                'avg_views': avg_views,
                'avg_forwards': avg_forwards
            },
            'top_messages': [
                {
                    'text': msg['text'][:200] + '...' if len(msg['text']) > 200 else msg['text'],
                    'views': msg.get('views', 0),
                    'forwards': msg.get('forwards', 0)
                }
                for msg in top_messages
            ]
        }
        
        # ç¼“å­˜ç»“æœ
        if channel_username not in self.message_cache:
            self.message_cache[channel_username] = []
        
        self.message_cache[channel_username].append(analysis)
        
        # é™åˆ¶ç¼“å­˜å¤§å°
        if len(self.message_cache[channel_username]) > 100:
            self.message_cache[channel_username] = self.message_cache[channel_username][-100:]
        
        return analysis
    
    async def monitor_all_channels(
        self,
        limit_per_channel: int = 20,
        since_minutes: int = 60
    ) -> List[Dict[str, Any]]:
        """
        ç›‘æ§æ‰€æœ‰é…ç½®çš„é¢‘é“
        
        Args:
            limit_per_channel: æ¯ä¸ªé¢‘é“è·å–æ¶ˆæ¯æ•°
            since_minutes: è·å–å¤šå°‘åˆ†é’Ÿå†…çš„æ¶ˆæ¯
        
        Returns:
            æ‰€æœ‰é¢‘é“çš„åˆ†æç»“æœ
        """
        logger.info(f"\n{'='*70}")
        logger.info(f"ğŸ”„ å¼€å§‹Telegramé¢‘é“ç›‘æ§ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"{'='*70}")
        
        results = []
        
        for channel in self.channels:
            try:
                # è·å–æ¶ˆæ¯
                messages = await self.fetch_channel_messages(
                    channel,
                    limit=limit_per_channel,
                    since_minutes=since_minutes
                )
                
                # åˆ†ææ¶ˆæ¯
                if messages:
                    analysis = self.analyze_messages(messages, channel)
                    results.append(analysis)
                    
                    # æ‰“å°æ‘˜è¦
                    sentiment = analysis.get('sentiment', {})
                    logger.info(f"ğŸ“¢ @{channel}: {analysis['message_count']}æ¡æ¶ˆæ¯, "
                              f"æƒ…ç»ª={sentiment['label']}, "
                              f"äº’åŠ¨={analysis['engagement']['avg_views']:.0f}æµè§ˆ")
                
                # é¿å…é€Ÿç‡é™åˆ¶
                await asyncio.sleep(2)
            
            except Exception as e:
                logger.error(f"ç›‘æ§é¢‘é“å¤±è´¥ @{channel}: {e}")
        
        logger.info(f"{'='*70}")
        logger.info(f"âœ… Telegramç›‘æ§å®Œæˆï¼Œå…±åˆ†æ {len(results)} ä¸ªé¢‘é“")
        logger.info(f"{'='*70}\n")
        
        return results
    
    def _generate_mock_messages(self, channel: str, limit: int) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ¨¡æ‹Ÿæ¶ˆæ¯ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        import random
        
        mock_texts = [
            "Bitcoin surges past $67,000 as institutional adoption accelerates ğŸš€",
            "Ethereum network upgrade scheduled for next week - major scalability improvements expected",
            "Whale Alert: 1,000 BTC transferred from unknown wallet to Binance",
            "SEC delays decision on Bitcoin ETF approval - market sentiment turns cautious",
            "Vitalik Buterin presents new Ethereum roadmap at developer conference",
            "Michael Saylor's MicroStrategy purchases additional 500 BTC",
            "Crypto market sees $1B in liquidations as Bitcoin drops 5% in hours",
            "New DeFi protocol launches with innovative yield farming mechanism",
            "Binance announces new trading pairs and zero-fee promotion",
            "Regulatory concerns mount as governments discuss crypto taxation"
        ]
        
        messages = []
        base_time = datetime.now()
        
        for i in range(min(limit, len(mock_texts))):
            messages.append({
                'id': 1000 + i,
                'channel': channel,
                'text': random.choice(mock_texts),
                'date': (base_time - timedelta(minutes=i*5)).isoformat(),
                'views': random.randint(1000, 50000),
                'forwards': random.randint(10, 500),
                'timestamp': datetime.now().isoformat()
            })
        
        return messages
    
    def get_summary_report(self, analyses: List[Dict[str, Any]]) -> str:
        """
        ç”ŸæˆTelegramç›‘æ§æ‘˜è¦æŠ¥å‘Š
        
        Args:
            analyses: é¢‘é“åˆ†æç»“æœåˆ—è¡¨
        
        Returns:
            æŠ¥å‘Šæ–‡æœ¬
        """
        if not analyses:
            return "æ— Telegramç›‘æ§æ•°æ®"
        
        report = []
        report.append("\n" + "="*70)
        report.append("ğŸ“± Telegramé¢‘é“ç›‘æ§æŠ¥å‘Š")
        report.append("="*70)
        report.append(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"ç›‘æ§é¢‘é“: {len(analyses)}ä¸ª")
        report.append("")
        
        # æ•´ä½“æƒ…ç»ªç»Ÿè®¡
        total_bullish = sum(1 for a in analyses if a.get('sentiment', {}).get('label') in ['BULLISH', 'SLIGHTLY_BULLISH'])
        total_bearish = sum(1 for a in analyses if a.get('sentiment', {}).get('label') in ['BEARISH', 'SLIGHTLY_BEARISH'])
        total_neutral = len(analyses) - total_bullish - total_bearish
        
        report.append("ã€æ•´ä½“æƒ…ç»ªã€‘")
        report.append(f"  çœ‹æ¶¨: {total_bullish}ä¸ªé¢‘é“")
        report.append(f"  çœ‹è·Œ: {total_bearish}ä¸ªé¢‘é“")
        report.append(f"  ä¸­æ€§: {total_neutral}ä¸ªé¢‘é“")
        report.append("")
        
        # é‡è¦äººç‰©æåŠæ±‡æ€»
        all_influencer_mentions = {}
        for analysis in analyses:
            for influencer, count in analysis.get('influencer_mentions', {}).items():
                if influencer not in all_influencer_mentions:
                    all_influencer_mentions[influencer] = 0
                all_influencer_mentions[influencer] += count
        
        if all_influencer_mentions:
            report.append("ã€é‡è¦äººç‰©æåŠã€‘")
            for influencer, count in sorted(all_influencer_mentions.items(), key=lambda x: x[1], reverse=True):
                name = influencer.replace('_', ' ').title()
                report.append(f"  {name}: {count}æ¬¡")
            report.append("")
        
        # å„é¢‘é“è¯¦æƒ…
        report.append("ã€é¢‘é“è¯¦æƒ…ã€‘")
        for analysis in analyses:
            channel_name = analysis.get('channel_name', analysis['channel'])
            msg_count = analysis['message_count']
            sentiment = analysis.get('sentiment', {})
            engagement = analysis.get('engagement', {})
            
            report.append(f"\n  ğŸ“¢ {channel_name} (@{analysis['channel']})")
            report.append(f"     æ¶ˆæ¯æ•°: {msg_count}")
            report.append(f"     æƒ…ç»ª: {sentiment.get('label', 'UNKNOWN')} (å¾—åˆ†: {sentiment.get('score', 0):.2f})")
            report.append(f"     äº’åŠ¨: å¹³å‡{engagement.get('avg_views', 0):.0f}æµè§ˆ, {engagement.get('avg_forwards', 0):.0f}è½¬å‘")
            
            # å…³é”®è¯æåŠ
            keyword_mentions = analysis.get('keyword_mentions', {})
            top_keywords = sorted(keyword_mentions.items(), key=lambda x: x[1], reverse=True)[:3]
            if top_keywords:
                keywords_str = ', '.join([f"{kw}({count})" for kw, count in top_keywords if count > 0])
                if keywords_str:
                    report.append(f"     çƒ­è¯: {keywords_str}")
        
        report.append("\n" + "="*70)
        
        return '\n'.join(report)
