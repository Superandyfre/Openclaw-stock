#!/usr/bin/env python3
"""
Gemini æ¨¡å‹æ™ºèƒ½ç®¡ç†å™¨ (2026ç‰ˆ)
æ ¹æ®ä»»åŠ¡ç±»å‹è‡ªåŠ¨é€‰æ‹©æœ€åˆé€‚çš„æ¨¡å‹ï¼Œé…é¢è€—å°½æ—¶è‡ªåŠ¨é™çº§
é™çº§é“¾ï¼šgemini-2.0-flash â†’ gemini-1.5-flash â†’ gemini-2.0-flash-lite â†’ DeepSeek
"""
import os
import asyncio
from typing import Optional, Literal
from loguru import logger

try:
    from google import genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    logger.warning("Google AI æœªå®‰è£…")

try:
    from openai import OpenAI as OpenAIClient
    OPENAI_SDK_AVAILABLE = True
except ImportError:
    OPENAI_SDK_AVAILABLE = False

try:
    from groq import Groq as GroqClient
    GROQ_SDK_AVAILABLE = True
except ImportError:
    GROQ_SDK_AVAILABLE = False


TaskType = Literal[
    'lightweight',      # è½»é‡ä»»åŠ¡ï¼šå…¬å‘Šæ ‡é¢˜åˆç­›ã€ç®€å•é—®ç­”
    'standard',         # æ ‡å‡†ä»»åŠ¡ï¼šæ—¥å¸¸ç›‘æ§ã€ä¸€èˆ¬æ¨è
    'complex',          # å¤æ‚ä»»åŠ¡ï¼šæ·±åº¦åˆ†æã€ç­–ç•¥ç ”åˆ¤
    'experimental'      # å®éªŒä»»åŠ¡ï¼šå‰æ²¿åŠŸèƒ½æµ‹è¯•
]


class GeminiModelManager:
    """Geminiæ¨¡å‹æ™ºèƒ½ç®¡ç†å™¨ï¼ˆå«è‡ªåŠ¨é™çº§é“¾ï¼‰"""

    # å…è´¹tierå®é™…æ¯æ—¥é…é¢ï¼ˆ2026å¹´2æœˆï¼‰ï¼š
    #   gemini-2.5-flash: 20æ¬¡/å¤©
    #   gemini-2.0-flash: 1500æ¬¡/å¤©ï¼ˆä½†æ¯ä¸ªAPI keyå…±äº«ï¼Œä»Šå¤©å·²è€—å°½åˆ™0ï¼‰
    #   gemini-2.0-flash-lite: 1500æ¬¡/å¤©
    #   gemini-1.5-flash: 1500æ¬¡/å¤©ï¼ˆå•ç‹¬é…é¢ï¼Œä¸ä¸2.0å…±äº«ï¼‰

    # é™çº§é“¾ï¼šé…é¢/ä¸å¯ç”¨æ—¶æŒ‰é¡ºåºå°è¯•ï¼Œç›´åˆ°æœ‰ä¸€ä¸ªæˆåŠŸ
    FALLBACK_CHAIN = [
        'gemini-2.0-flash',
        'gemini-2.0-flash-lite',
    ]

    MODEL_CONFIG = {
        'lightweight': {
            'name': 'gemini-2.0-flash-lite',
            'description': 'è½»é‡çº§æ¨¡å‹ï¼Œé…é¢å……è¶³',
            'use_cases': ['å…¬å‘Šæ ‡é¢˜ç­›é€‰', 'ç®€å•é—®ç­”', 'å…³é”®è¯æå–'],
            'quota': 'å…è´¹: 1500æ¬¡/å¤©'
        },
        'standard': {
            'name': 'gemini-2.0-flash',
            'description': 'Gemini 2.0 Flashï¼Œæ—¥å¸¸å¯¹è¯ä¸»åŠ›æ¨¡å‹',
            'use_cases': ['æ—¥å¸¸ç›¯ç›˜', 'ä¸€èˆ¬æ¨è', 'æƒ…æ„Ÿåˆ†æ', 'è‡ªç„¶è¯­è¨€ç†è§£'],
            'quota': 'å…è´¹: 1500æ¬¡/å¤©'
        },
        'complex': {
            'name': 'gemini-2.5-flash',
            'description': 'Gemini 2.5 Flashï¼Œæ·±åº¦åˆ†æï¼ˆé…é¢æœ‰é™ï¼‰',
            'use_cases': ['æ·±åº¦å¸‚åœºåˆ†æ', 'äº¤æ˜“ç­–ç•¥åˆ¤æ–­', 'é£é™©è¯„ä¼°', 'é•¿æ–‡æœ¬ç ”æŠ¥åˆ†æ'],
            'quota': 'å…è´¹: 20æ¬¡/å¤©'
        },
        'experimental': {
            'name': 'gemini-2.0-flash',
            'description': 'å®éªŒæ€§åŠŸèƒ½ï¼Œä½¿ç”¨2.0 Flash',
            'use_cases': ['å‰æ²¿åŠŸèƒ½æµ‹è¯•', 'æé•¿ä¸Šä¸‹æ–‡å¤„ç†'],
            'quota': 'å…è´¹: 1500æ¬¡/å¤©'
        }
    }
    
    def __init__(self, api_key: Optional[str] = None, default_task_type: TaskType = 'standard'):
        """
        åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨

        Args:
            api_key: Google AI APIå¯†é’¥
            default_task_type: é»˜è®¤ä»»åŠ¡ç±»å‹
        """
        self.api_key = api_key or os.getenv('GOOGLE_AI_API_KEY')
        self.default_task_type = default_task_type
        self.genai_client = None
        self.current_model_name = None
        self.deepseek_client = None
        self.groq_client = None

        if not GENAI_AVAILABLE:
            logger.error("Google AI SDK æœªå®‰è£…")
            return

        if not self.api_key:
            logger.error("GOOGLE_AI_API_KEY æœªè®¾ç½®")
            return

        # åˆ›å»º Gemini Client (æ–°API)
        try:
            self.genai_client = genai.Client(api_key=self.api_key)
            logger.info("âœ… Gemini Client åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"åˆ›å»ºGemini Clientå¤±è´¥: {e}")
            return

        # åˆå§‹åŒ– Groq å®¢æˆ·ç«¯ï¼ˆlightweight é¦–é€‰ï¼Œ~0.5s å»¶è¿Ÿï¼‰
        groq_key = os.getenv('GROQ_API_KEY')
        if groq_key and GROQ_SDK_AVAILABLE:
            try:
                self.groq_client = GroqClient(api_key=groq_key)
                logger.info("âœ… Groq å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼ˆlightweight è·¯ç”±é¦–é€‰ï¼‰")
            except Exception as e:
                logger.warning(f"Groq åˆå§‹åŒ–å¤±è´¥: {e}")
        elif groq_key and not GROQ_SDK_AVAILABLE:
            logger.warning("âš ï¸ groq åŒ…æœªå®‰è£…ï¼ˆpip install groqï¼‰ï¼Œè·³è¿‡ Groq")
        else:
            logger.info("â„¹ï¸ GROQ_API_KEY æœªè®¾ç½®ï¼Œè·³è¿‡ Groq")

        # åˆå§‹åŒ– DeepSeek å¤‡ç”¨å®¢æˆ·ç«¯
        deepseek_key = os.getenv('DEEPSEEK_API_KEY')
        if deepseek_key and OPENAI_SDK_AVAILABLE:
            try:
                self.deepseek_client = OpenAIClient(
                    api_key=deepseek_key,
                    base_url='https://api.deepseek.com'
                )
                logger.info("âœ… DeepSeek å¤‡ç”¨å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.warning(f"DeepSeek åˆå§‹åŒ–å¤±è´¥: {e}")
        elif not deepseek_key:
            logger.info("â„¹ï¸ DEEPSEEK_API_KEY æœªè®¾ç½®ï¼Œè·³è¿‡DeepSeekå¤‡ç”¨")
        elif not OPENAI_SDK_AVAILABLE:
            logger.warning("âš ï¸ openai åŒ…æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨DeepSeekå¤‡ç”¨ï¼ˆpip install openaiï¼‰")

        # è®¾ç½®å½“å‰é»˜è®¤æ¨¡å‹åç§°
        self.current_model_name = self.MODEL_CONFIG[default_task_type]['name']
    
    def get_model(self, task_type: TaskType = None):
        """
        è·å–æŒ‡å®šä»»åŠ¡ç±»å‹çš„æ¨¡å‹åç§°
        
        Args:
            task_type: ä»»åŠ¡ç±»å‹ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤ç±»å‹
        
        Returns:
            æ¨¡å‹åç§°å­—ç¬¦ä¸²
        """
        task_type = task_type or self.default_task_type
        config = self.MODEL_CONFIG.get(task_type)
        if config:
            self.current_model_name = config['name']
            logger.info(f"âœ… é€‰æ‹©Geminiæ¨¡å‹: {self.current_model_name} ({config['description']})")
            return self.current_model_name
        return None
    
    def _call_gemini_model(self, model_name: str, prompt: str) -> str:
        """è°ƒç”¨æŒ‡å®šçš„Geminiæ¨¡å‹ (åŒæ­¥)"""
        if not self.genai_client:
            raise RuntimeError("Gemini Client æœªåˆå§‹åŒ–")
        
        response = self.genai_client.models.generate_content(
            model=model_name,
            contents=prompt
        )
        return response.text.strip()

    async def _call_groq(self, prompt: str, model: str = 'llama-3.3-70b-versatile') -> Optional[str]:
        """è°ƒç”¨ Groq LPU æ¨ç†ï¼ˆæä½å»¶è¿Ÿï¼Œ~0.5sï¼‰"""
        if not self.groq_client:
            return None
        def _sync():
            resp = self.groq_client.chat.completions.create(
                model=model,
                messages=[{'role': 'user', 'content': prompt}],
                max_tokens=512,
                temperature=0.3,
            )
            return resp.choices[0].message.content.strip()
        try:
            text = await asyncio.to_thread(_sync)
            logger.info(f"âœ… Groq ({model}) å“åº”æˆåŠŸ")
            return text
        except Exception as e:
            logger.warning(f"âš ï¸ Groq è°ƒç”¨å¤±è´¥: {e}")
            return None

    async def generate_with_fallback(self, prompt: str, task_type: TaskType = 'standard') -> Optional[str]:
        """
        è°ƒç”¨LLMï¼ŒæŒ‰ä¼˜å…ˆçº§é¡ºåºå°è¯•ï¼š
        ã€ä¸´æ—¶ç­–ç•¥ï¼šDeepSeek æœ€é«˜ä¼˜å…ˆã€‘
          1. DeepSeekï¼ˆä¸­å›½ç›´è¿ï¼Œæœ€ç¨³å®šï¼‰
          2. Groqï¼ˆlightweight ä»»åŠ¡å¤‡ç”¨ï¼šæœ€ä½å»¶è¿Ÿï¼‰
          3. Gemini é™çº§é“¾ï¼ˆgemini-2.0-flash â†’ gemini-2.0-flash-liteï¼‰
        æ¢å¤åŸç­–ç•¥ï¼šæ¢å¤ .bak å¤‡ä»½è¦†ç›–æ­¤æ–‡ä»¶å³å¯ã€‚
        """
        # â”€â”€ 1. DeepSeek æœ€é«˜ä¼˜å…ˆï¼ˆä¸­å›½ç›´è¿ç¨³å®šï¼‰â”€â”€
        if self.deepseek_client:
            try:
                def _call_deepseek():
                    resp = self.deepseek_client.chat.completions.create(
                        model='deepseek-chat',
                        messages=[{'role': 'user', 'content': prompt}],
                        max_tokens=1024,
                        temperature=0.3,
                    )
                    return resp.choices[0].message.content.strip()
                text = await asyncio.to_thread(_call_deepseek)
                if text:
                    logger.info("âœ… DeepSeek å“åº”æˆåŠŸï¼ˆæœ€é«˜ä¼˜å…ˆï¼‰")
                    return text
            except Exception as e:
                err = str(e)
                if '402' in err or 'Insufficient Balance' in err:
                    logger.error("âŒ DeepSeek ä½™é¢ä¸è¶³ï¼Œé™çº§åˆ° Groq/Gemini")
                elif '401' in err:
                    logger.error("âŒ DeepSeek API Key æ— æ•ˆï¼Œé™çº§åˆ° Groq/Gemini")
                else:
                    logger.warning(f"âš ï¸ DeepSeek è°ƒç”¨å¤±è´¥: {err[:80]}ï¼Œé™çº§...")

        # â”€â”€ 2. Groq å¤‡ç”¨ï¼ˆlightweight ä¼˜å…ˆï¼Œå»¶è¿Ÿæä½ï¼‰â”€â”€
        if task_type == 'lightweight' and self.groq_client:
            text = await self._call_groq(prompt)
            if text:
                return text
            logger.warning("âš ï¸ Groq å¤±è´¥ï¼Œé™çº§åˆ° Gemini...")

        # â”€â”€ 3. Gemini é™çº§é“¾ (ä½¿ç”¨æ–°API) â”€â”€
        if not self.genai_client:
            logger.error("âŒ Gemini Client æœªåˆå§‹åŒ–")
            return None
            
        primary = self.MODEL_CONFIG.get(task_type, {}).get('name', 'gemini-2.0-flash')
        chain = [primary] + [m for m in self.FALLBACK_CHAIN if m != primary]

        for model_name in chain:
            try:
                text = await asyncio.to_thread(self._call_gemini_model, model_name, prompt)
                if model_name != primary:
                    logger.warning(f"âš ï¸ å·²é™çº§ä½¿ç”¨: {model_name}")
                else:
                    logger.info(f"âœ… ä½¿ç”¨æ¨¡å‹: {model_name}")
                return text
            except Exception as e:
                err = str(e)
                if '429' in err or '404' in err or 'quota' in err.lower() or 'RESOURCE_EXHAUSTED' in err or 'not found' in err.lower():
                    logger.warning(f"âš ï¸ {model_name} ä¸å¯ç”¨ï¼ˆ{err[:60]}ï¼‰ï¼Œå°è¯•ä¸‹ä¸€ä¸ª...")
                    continue
                else:
                    logger.error(f"æ¨¡å‹ {model_name} è°ƒç”¨å¤±è´¥ï¼ˆéé…é¢é—®é¢˜ï¼‰: {e}")
                    raise

        # â”€â”€ 4. Groq æœ€åå…œåº•ï¼ˆstandard/complexï¼‰â”€â”€
        if task_type != 'lightweight' and self.groq_client:
            logger.warning("âš ï¸ æ‰€æœ‰Geminiè€—å°½ï¼Œåˆ‡æ¢åˆ° Groq æœ€ç»ˆå…œåº•...")
            text = await self._call_groq(prompt)
            if text:
                return text

        logger.error("âŒ æ‰€æœ‰AIæ¨¡å‹å‡ä¸å¯ç”¨")
        return None

    def switch_to(self, task_type: TaskType):
        """
        åˆ‡æ¢åˆ°æŒ‡å®šä»»åŠ¡ç±»å‹çš„æ¨¡å‹

        Args:
            task_type: ä»»åŠ¡ç±»å‹

        Returns:
            æ¨¡å‹åç§°
        """
        return self.get_model(task_type)
    
    def get_model_info(self, task_type: TaskType = None) -> dict:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        task_type = task_type or self.default_task_type
        return self.MODEL_CONFIG.get(task_type, {})
    
    def list_available_models(self):
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹é…ç½®"""
        logger.info("\nğŸ“‹ å¯ç”¨çš„Geminiæ¨¡å‹é…ç½®ï¼š\n")
        
        for task_type, config in self.MODEL_CONFIG.items():
            logger.info(f"ğŸ”¹ {task_type.upper()}")
            logger.info(f"   æ¨¡å‹: {config['name']}")
            logger.info(f"   æè¿°: {config['description']}")
            logger.info(f"   ç”¨é€”: {', '.join(config['use_cases'])}")
            logger.info("")


# ä¾¿æ·å‡½æ•°
def get_lightweight_model(api_key: Optional[str] = None):
    """è·å–è½»é‡çº§æ¨¡å‹ç®¡ç†å™¨ï¼ˆæœ€çœé’±ï¼‰"""
    manager = GeminiModelManager(api_key, default_task_type='lightweight')
    return manager


def get_standard_model(api_key: Optional[str] = None):
    """è·å–æ ‡å‡†æ¨¡å‹ç®¡ç†å™¨ï¼ˆæ—¥å¸¸ä½¿ç”¨ï¼‰"""
    manager = GeminiModelManager(api_key, default_task_type='standard')
    return manager


def get_complex_model(api_key: Optional[str] = None):
    """è·å–å¤æ‚åˆ†ææ¨¡å‹ç®¡ç†å™¨ï¼ˆæ·±åº¦æ¨ç†ï¼‰"""
    manager = GeminiModelManager(api_key, default_task_type='complex')
    return manager


def get_experimental_model(api_key: Optional[str] = None):
    """è·å–å®éªŒæ¨¡å‹ç®¡ç†å™¨ï¼ˆæœ€æ–°æŠ€æœ¯ï¼‰"""
    manager = GeminiModelManager(api_key, default_task_type='experimental')
    return manager


if __name__ == '__main__':
    # æµ‹è¯•
    manager = GeminiModelManager()
    manager.list_available_models()
    
    # æµ‹è¯•æ¨¡å‹åˆ‡æ¢
    print("\næµ‹è¯•æ¨¡å‹åˆ‡æ¢ï¼š")
    
    for task_type in ['lightweight', 'standard', 'complex']:
        model_name = manager.get_model(task_type)
        if model_name:
            print(f"âœ… {task_type}: {model_name}")
        else:
            print(f"âŒ {task_type}: åŠ è½½å¤±è´¥")
